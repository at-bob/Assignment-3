{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95a452ae",
   "metadata": {},
   "source": [
    "# Athleteâ€™s Temple Business Chatbot (Gradio + OpenAI/Gemini)\n",
    "\n",
    "This notebook implements a business chatbot that can:\n",
    "- **Answer questions** about the business (from `/me/business_summary.txt`),\n",
    "- **Collect leads** (name, email, notes â†’ CSV),\n",
    "- **Record feedback / unanswered questions** (tool calls â†’ CSV),\n",
    "- Run with **OpenAI** *or* **Gemini** (choose in config),\n",
    "- **Deploy via Gradio** (mobile-friendly)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1ba1a6",
   "metadata": {},
   "source": [
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef2e4822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Using cached gradio-5.49.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting anyio<5.0,>=3.0 (from gradio)\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting audioop-lts<1.0 (from gradio)\n",
      "  Using cached audioop_lts-0.2.2-cp313-abi3-macosx_11_0_arm64.whl.metadata (2.0 kB)\n",
      "Collecting brotli>=1.1.0 (from gradio)\n",
      "  Using cached Brotli-1.1.0-cp313-cp313-macosx_10_13_universal2.whl.metadata (5.5 kB)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Using cached fastapi-0.119.0-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Using cached ffmpy-0.6.3-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.13.3 (from gradio)\n",
      "  Using cached gradio_client-1.13.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Using cached groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting httpx<1.0,>=0.24.1 (from gradio)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting huggingface-hub<2.0,>=0.33.5 (from gradio)\n",
      "  Using cached huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting jinja2<4.0 (from gradio)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting markupsafe<4.0,>=2.0 (from gradio)\n",
      "  Using cached markupsafe-3.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Collecting numpy<3.0,>=1.0 (from gradio)\n",
      "  Using cached numpy-2.3.4-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Using cached orjson-3.11.3-cp313-cp313-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from gradio) (25.0)\n",
      "Collecting pillow<12.0,>=8.0 (from gradio)\n",
      "  Using cached pillow-11.3.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Collecting pydantic<2.12,>=2.0 (from gradio)\n",
      "  Using cached pydantic-2.11.10-py3-none-any.whl.metadata (68 kB)\n",
      "Collecting pydub (from gradio)\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pyyaml<7.0,>=5.0 (from gradio)\n",
      "  Using cached pyyaml-6.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Using cached ruff-0.14.1-py3-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Using cached safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Using cached starlette-0.48.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Using cached tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Using cached typer-0.19.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting typing-extensions~=4.0 (from gradio)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Using cached uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting fsspec (from gradio-client==1.13.3->gradio)\n",
      "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting websockets<16.0,>=13.0 (from gradio-client==1.13.3->gradio)\n",
      "  Using cached websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting idna>=2.8 (from anyio<5.0,>=3.0->gradio)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting sniffio>=1.1 (from anyio<5.0,>=3.0->gradio)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting certifi (from httpx<1.0,>=0.24.1->gradio)\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1.0,>=0.24.1->gradio)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting filelock (from huggingface-hub<2.0,>=0.33.5->gradio)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting requests (from huggingface-hub<2.0,>=0.33.5->gradio)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub<2.0,>=0.33.5->gradio)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<2.0,>=0.33.5->gradio)\n",
      "  Using cached hf_xet-1.1.10-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.7 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<2.12,>=2.0->gradio)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<2.12,>=2.0->gradio)\n",
      "  Using cached pydantic_core-2.33.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<2.12,>=2.0->gradio)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting click>=8.0.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->huggingface-hub<2.0,>=0.33.5->gradio)\n",
      "  Using cached charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl.metadata (37 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub<2.0,>=0.33.5->gradio)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Downloading gradio-5.49.1-py3-none-any.whl (63.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.5/63.5 MB\u001b[0m \u001b[31m30.2 kB/s\u001b[0m  \u001b[33m0:38:10\u001b[0mm0:00:04\u001b[0m01:11\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.13.3-py3-none-any.whl (325 kB)\n",
      "Using cached pandas-2.3.3-cp313-cp313-macosx_11_0_arm64.whl (10.7 MB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Downloading audioop_lts-0.2.2-cp313-abi3-macosx_11_0_arm64.whl (26 kB)\n",
      "Using cached fastapi-0.119.0-py3-none-any.whl (107 kB)\n",
      "Downloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "Using cached hf_xet-1.1.10-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached markupsafe-3.0.3-cp313-cp313-macosx_11_0_arm64.whl (12 kB)\n",
      "Downloading numpy-2.3.4-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m70.0 kB/s\u001b[0m  \u001b[33m0:02:32\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.11.3-cp313-cp313-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (238 kB)\n",
      "Using cached pillow-11.3.0-cp313-cp313-macosx_11_0_arm64.whl (4.7 MB)\n",
      "Downloading pydantic-2.11.10-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp313-cp313-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m288.9 kB/s\u001b[0m  \u001b[33m0:00:06\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pyyaml-6.0.3-cp313-cp313-macosx_11_0_arm64.whl (173 kB)\n",
      "Downloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Using cached starlette-0.48.0-py3-none-any.whl (73 kB)\n",
      "Downloading tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
      "Downloading typer-0.19.2-py3-none-any.whl (46 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl (173 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading Brotli-1.1.0-cp313-cp313-macosx_10_13_universal2.whl (815 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m815.7/815.7 kB\u001b[0m \u001b[31m501.3 kB/s\u001b[0m  \u001b[33m0:00:01\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading ruff-0.14.1-py3-none-macosx_11_0_arm64.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m34.6 kB/s\u001b[0m  \u001b[33m0:02:19\u001b[0mm0:00:07\u001b[0m00:15\u001b[0m\n",
      "\u001b[?25hUsing cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Downloading ffmpy-0.6.3-py3-none-any.whl (5.5 kB)\n",
      "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl (208 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Installing collected packages: pytz, pydub, brotli, websockets, urllib3, tzdata, typing-extensions, tqdm, tomlkit, sniffio, shellingham, semantic-version, ruff, pyyaml, python-multipart, python-dotenv, pillow, orjson, numpy, mdurl, markupsafe, idna, hf-xet, h11, groovy, fsspec, filelock, ffmpy, click, charset_normalizer, certifi, audioop-lts, annotated-types, aiofiles, uvicorn, typing-inspection, requests, pydantic-core, pandas, markdown-it-py, jinja2, httpcore, anyio, starlette, rich, pydantic, huggingface-hub, httpx, typer, safehttpx, gradio-client, fastapi, gradio\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53/53\u001b[0m [gradio] [gradio] [httpx]gface-hub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiofiles-24.1.0 annotated-types-0.7.0 anyio-4.11.0 audioop-lts-0.2.2 brotli-1.1.0 certifi-2025.10.5 charset_normalizer-3.4.4 click-8.3.0 fastapi-0.119.0 ffmpy-0.6.3 filelock-3.20.0 fsspec-2025.9.0 gradio-5.49.1 gradio-client-1.13.3 groovy-0.1.2 h11-0.16.0 hf-xet-1.1.10 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.35.3 idna-3.11 jinja2-3.1.6 markdown-it-py-4.0.0 markupsafe-3.0.3 mdurl-0.1.2 numpy-2.3.4 orjson-3.11.3 pandas-2.3.3 pillow-11.3.0 pydantic-2.11.10 pydantic-core-2.33.2 pydub-0.25.1 python-dotenv-1.1.1 python-multipart-0.0.20 pytz-2025.2 pyyaml-6.0.3 requests-2.32.5 rich-14.2.0 ruff-0.14.1 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 sniffio-1.3.1 starlette-0.48.0 tomlkit-0.13.3 tqdm-4.67.1 typer-0.19.2 typing-extensions-4.15.0 typing-inspection-0.4.2 tzdata-2025.2 urllib3-2.5.0 uvicorn-0.38.0 websockets-15.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Core deps\n",
    "%pip install gradio python-dotenv pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2be20db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip -q install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad24d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, json, textwrap\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e781a7",
   "metadata": {},
   "source": [
    "### 2. Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f8356aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Provider: openai\n",
      "ðŸ“„ Summary file: /Users/adamtai/Desktop/GPCS/4. FALL 2025/EECE 798S/Assignments/Assignment 3/me/business_summary.txt\n",
      "ðŸ—‚ï¸ leads.csv: /Users/adamtai/Desktop/GPCS/4. FALL 2025/EECE 798S/Assignments/Assignment 3/leads.csv\n",
      "ðŸ—‚ï¸ feedback.csv: /Users/adamtai/Desktop/GPCS/4. FALL 2025/EECE 798S/Assignments/Assignment 3/feedback.csv\n"
     ]
    }
   ],
   "source": [
    "# Load .env \n",
    "load_dotenv()\n",
    "\n",
    "# === Choose provider here ===\n",
    "PROVIDER = os.getenv(\"PROVIDER\", \"openai\").lower().strip() \n",
    "\n",
    "# API Key\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\").strip()\n",
    "\n",
    "# Basic guards\n",
    "if PROVIDER == \"openai\" and not OPENAI_API_KEY:\n",
    "    print(\"âš ï¸ Set OPENAI_API_KEY in environment or .env\")\n",
    "\n",
    "# Paths\n",
    "ME_DIR = Path(\"me\")\n",
    "SUMMARY_TXT = ME_DIR / \"business_summary.txt\"\n",
    "LEADS_CSV = Path(\"leads.csv\")\n",
    "FEEDBACK_CSV = Path(\"feedback.csv\")\n",
    "\n",
    "ME_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Create CSVs with headers if absent\n",
    "if not LEADS_CSV.exists():\n",
    "    pd.DataFrame(columns=[\"timestamp\",\"name\",\"email\",\"notes\",\"source\"]).to_csv(LEADS_CSV, index=False)\n",
    "if not FEEDBACK_CSV.exists():\n",
    "    pd.DataFrame(columns=[\"timestamp\",\"user_message\",\"model_answer\",\"status\",\"tag\"]).to_csv(FEEDBACK_CSV, index=False)\n",
    "\n",
    "print(f\"âœ… Provider: {PROVIDER}\")\n",
    "print(f\"ðŸ“„ Summary file: {SUMMARY_TXT.resolve()}\")\n",
    "print(f\"ðŸ—‚ï¸ leads.csv: {LEADS_CSV.resolve()}\")\n",
    "print(f\"ðŸ—‚ï¸ feedback.csv: {FEEDBACK_CSV.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fa482a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OpenAI client initialized.\n"
     ]
    }
   ],
   "source": [
    "# --- INIT OPENAI CLIENT SAFELY ---\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# 1) Ensure your API key is set (in .env or environment)\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise RuntimeError(\n",
    "        \"OPENAI_API_KEY not set. Add it to your environment or a .env file and rerun this cell.\"\n",
    "    )\n",
    "\n",
    "# 2) Create a single global client the rest of the notebook can use\n",
    "client = OpenAI()  # picks up OPENAI_API_KEY from the environment\n",
    "\n",
    "# 3) Optional quick sanity check (lists your accessible models)\n",
    "try:\n",
    "    _ = client.models.list()\n",
    "    print(\"âœ… OpenAI client initialized.\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"OpenAI init failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd6ceb1",
   "metadata": {},
   "source": [
    "### 3. Load Business Knowledge\n",
    "We read `/me/business_summary.txt` as the authoritative context.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc8d3e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Summary loaded (first 400 chars):\n",
      " Athleteâ€™s Temple\n",
      "Mission: To empower individuals of all levels to unlock their physical and mental potential\n",
      "through expert-led fitness, martial arts, and personalized coaching programs.\n",
      "Services Offered:\n",
      "â€¢ Regular Gym Membership (Full Access to Training Facilities)\n",
      "â€¢ Martial Arts Classes â€” Taekwondo, Brazilian Jiu-Jitsu, Muay Thai, and Open Mat Sessions\n",
      "â€¢ Personal Training Programs with Certified ...\n"
     ]
    }
   ],
   "source": [
    "if not SUMMARY_TXT.exists():\n",
    "    SUMMARY_TXT.write_text(textwrap.dedent(\"\"\"\\\n",
    "        Athlete's Temple\n",
    "\n",
    "        Mission: To empower individuals of all levels to unlock their physical and mental potential through expert-led fitness, martial arts, and personalized coaching programs.\n",
    "\n",
    "        Services Offered:\n",
    "        â€¢ Regular Gym Membership (Full Access to Training Facilities)\n",
    "        â€¢ Martial Arts Classes â€” Taekwondo, Brazilian Jiu-Jitsu, Muay Thai, and Open Mat Sessions\n",
    "        â€¢ Personal Training Programs with Certified Coaches\n",
    "        â€¢ Calisthenics Classes\n",
    "        â€¢ Snack Bar & Gym Supplements - sports drinks, refreshments, protein bars, and energy bars\n",
    "        \n",
    "        Our Team:\n",
    "        Coach Dan - Founder & Head Coach: A former national Taekwondo athlete and certified strength coach with 15+ years in martial arts instruction and athlete conditioning.\n",
    "        Coach Park Lee - Head of Personal Training: Certified fitness and wellness specialist, helping clients achieve lasting transformations through tailored programs and lifestyle guidance.\n",
    "        Coach Tamer - BJJ Lead Instructor: Brazilian Jiu-Jitsu black belt and professional competitor, passionate about technical excellence and personal growth through combat sports.\n",
    "        Coach Majd - Calisthenics Lead Instructor: A jacked calisthenics athlete with over 8 years of experience, leading multiple classes for different age groups, from kids to adults.\n",
    "        Coach Lynn - Muay Thai Lead Instructor: Young muay thai prodigy, reigning national champion leading and guiding others on their own journey to similar successes.\n",
    "        Bassel Hani - Operations & Financial Manager: With 10+ years in fitness operations and finance, Bassel keeps Athlete's Temple running smoothly - managing budgets, memberships, and logistics with precision and efficiency.\n",
    "        \n",
    "        Unique Value Proposition:\n",
    "        Athlete's Temple Training Club stands out as a hybrid fitness and martial arts hub - blending elite coaching, science-backed programming, and a strong community culture. Whether you're training for performance, confidence, or balance, Athlete's Temple provides the structure, motivation, and expert guidance to help you thrive.\n",
    "    \"\"\").strip(), encoding=\"utf-8\")\n",
    "\n",
    "KB_TEXT = SUMMARY_TXT.read_text(encoding=\"utf-8\")\n",
    "print(\"âœ… Summary loaded (first 400 chars):\\n\", KB_TEXT[:400], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7be54a9",
   "metadata": {},
   "source": [
    "### 4. Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12e6cc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_customer_interest(name: str, email: str, notes: str, source: str=\"chat\"):\n",
    "    row = {\n",
    "        \"timestamp\": datetime.utcnow().isoformat(),\n",
    "        \"name\": (name or \"\").strip(),\n",
    "        \"email\": (email or \"\").strip(),\n",
    "        \"notes\": (notes or \"\").strip(),\n",
    "        \"source\": source\n",
    "    }\n",
    "    df = pd.read_csv(LEADS_CSV)\n",
    "    df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
    "    df.to_csv(LEADS_CSV, index=False)\n",
    "    return {\"ok\": True, \"saved\": row}\n",
    "\n",
    "def record_feedback(user_message: str, reason: str=\"out_of_scope_or_missing\"):\n",
    "    row = {\n",
    "        \"timestamp\": datetime.utcnow().isoformat(),\n",
    "        \"user_message\": (user_message or \"\").strip(),\n",
    "        \"model_answer\": \"\",\n",
    "        \"status\": \"unanswered\",\n",
    "        \"tag\": reason\n",
    "    }\n",
    "    df = pd.read_csv(FEEDBACK_CSV)\n",
    "    df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
    "    df.to_csv(FEEDBACK_CSV, index=False)\n",
    "    return {\"ok\": True, \"saved\": row}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b7ab45",
   "metadata": {},
   "source": [
    "### 5. System prompt & tool schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d14b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_DIRECTIVES = textwrap.dedent(f\"\"\"\n",
    "You are the official concierge for Athlete's Temple (hybrid fitness & martial arts club).\n",
    "Use ONLY the business summary as your ground truth. If a question asks for missing info\n",
    "(e.g., pricing, schedule, policies), call the tool `record_feedback` with the user question,\n",
    "give the user a brief friendly message, and invite them to share their contact details by asking\n",
    "\"Would you like to leave your name and email so a coach can follow up with you?\"\n",
    "\n",
    "If the user expresses interest or shares contact details, call the tool `record_customer_interest`\n",
    "with name, email, and a short note (their message or intent).\n",
    "\n",
    "Otherwise (when the answer is fully covered by the summary), do NOT ask for contact details\n",
    "and do NOT mention follow-up.\n",
    "\n",
    "Be concise, factual, and friendly.\n",
    "\"\"\").strip()\n",
    "\n",
    "def build_user_content(user_message: str) -> str:\n",
    "    return textwrap.dedent(f\"\"\"\n",
    "    [BUSINESS SUMMARY]\n",
    "    {KB_TEXT}\n",
    "\n",
    "    [USER]\n",
    "    {user_message}\n",
    "    \"\"\").strip()\n",
    "\n",
    "# OpenAI tool (function) schemas\n",
    "TOOLS = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"record_customer_interest\",\n",
    "            \"description\": \"Save a potential customer's contact details and note for follow-up.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\":  {\"type\": \"string\", \"description\": \"Customer name, if provided.\"},\n",
    "                    \"email\": {\"type\": \"string\", \"description\": \"Customer email, if provided.\"},\n",
    "                    \"notes\": {\"type\": \"string\", \"description\": \"Short note about their interest or request.\"}\n",
    "                },\n",
    "                \"required\": []\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"record_feedback\",\n",
    "            \"description\": \"Log a question that couldn't be answered from the business summary.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"user_message\": {\"type\": \"string\", \"description\": \"The unanswered question from the user.\"},\n",
    "                    \"reason\": {\"type\": \"string\", \"enum\": [\"out_of_scope_or_missing\",\"other\"], \"description\": \"Why it was logged.\"}\n",
    "                },\n",
    "                \"required\": [\"user_message\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cbda70",
   "metadata": {},
   "source": [
    "### 6. Execute modelâ€™s tool calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a217b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dispatch_tool_call(name: str, arguments: dict):\n",
    "    try:\n",
    "        if name == \"record_customer_interest\":\n",
    "            return record_customer_interest(\n",
    "                name=arguments.get(\"name\",\"\"),\n",
    "                email=arguments.get(\"email\",\"\"),\n",
    "                notes=arguments.get(\"notes\",\"\"),\n",
    "                source=\"chat_auto\"\n",
    "            )\n",
    "        elif name == \"record_feedback\":\n",
    "            return record_feedback(\n",
    "                user_message=arguments.get(\"user_message\",\"\"),\n",
    "                reason=arguments.get(\"reason\",\"out_of_scope_or_missing\")\n",
    "            )\n",
    "        else:\n",
    "            return {\"ok\": False, \"error\": f\"Unknown tool: {name}\"}\n",
    "    except Exception as e:\n",
    "        return {\"ok\": False, \"error\": str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fa8e25",
   "metadata": {},
   "source": [
    "### 7. Agentic chat with tool loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c41cc1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _msg_to_dict(msg):\n",
    "    \"\"\"\n",
    "    Convert OpenAI SDK message object to a plain dict, preserving tool_calls.\n",
    "    \"\"\"\n",
    "    d = {\"role\": msg.role}\n",
    "    # content can be None or string\n",
    "    if getattr(msg, \"content\", None) is not None:\n",
    "        d[\"content\"] = msg.content\n",
    "    else:\n",
    "        d[\"content\"] = \"\"\n",
    "\n",
    "    # Preserve tool_calls if present\n",
    "    if getattr(msg, \"tool_calls\", None):\n",
    "        calls = []\n",
    "        for tc in msg.tool_calls:\n",
    "            calls.append({\n",
    "                \"id\": tc.id,\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": tc.function.name,\n",
    "                    \"arguments\": tc.function.arguments or \"{}\"\n",
    "                }\n",
    "            })\n",
    "        d[\"tool_calls\"] = calls\n",
    "    return d\n",
    "\n",
    "\n",
    "def agentic_chat_once(user_message: str, history_messages: list):\n",
    "    \"\"\"\n",
    "    Single turn with tool-calling:\n",
    "    1) Add system + user\n",
    "    2) Call model (allows tools)\n",
    "    3) If tool_calls present -> run tools, append tool results, call model again\n",
    "    4) Return final text and updated history\n",
    "    \"\"\"\n",
    "    # 1) Ensure system message at start\n",
    "    if not history_messages or history_messages[0].get(\"role\") != \"system\":\n",
    "        history_messages = [{\"role\": \"system\", \"content\": SYSTEM_DIRECTIVES}] + history_messages\n",
    "\n",
    "    # Add user with KB context\n",
    "    history_messages = history_messages + [{\"role\": \"user\", \"content\": build_user_content(user_message)}]\n",
    "\n",
    "    # 2) First call (tool-choice = auto)\n",
    "    resp = client.chat.completions.create(\n",
    "        model=os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\"),\n",
    "        messages=history_messages,\n",
    "        tools=TOOLS,\n",
    "        tool_choice=\"auto\",\n",
    "        temperature=float(os.getenv(\"OPENAI_TEMPERATURE\",\"0.6\")),\n",
    "        top_p=float(os.getenv(\"OPENAI_TOP_P\",\"0.9\")),\n",
    "        max_tokens=int(os.getenv(\"OPENAI_MAX_TOKENS\",\"400\"))\n",
    "    )\n",
    "    msg = resp.choices[0].message\n",
    "\n",
    "    # IMPORTANT: append the assistant message WITH ITS tool_calls preserved\n",
    "    history_messages.append(_msg_to_dict(msg))\n",
    "\n",
    "    tool_calls = msg.tool_calls or []\n",
    "    feedback_logged = False\n",
    "\n",
    "    if tool_calls:\n",
    "        # 3) Execute each tool call and append a corresponding tool message\n",
    "        for tc in tool_calls:\n",
    "            fn_name = tc.function.name\n",
    "            fn_args = json.loads(tc.function.arguments or \"{}\")\n",
    "            result = _dispatch_tool_call(fn_name, fn_args)\n",
    "\n",
    "            if fn_name == \"record_feedback\":\n",
    "                feedback_logged = True\n",
    "\n",
    "            # Each tool message must reference the EXACT tool_call_id\n",
    "            history_messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tc.id,\n",
    "                \"name\": fn_name,\n",
    "                \"content\": json.dumps(result)\n",
    "            })\n",
    "\n",
    "        # 4) Second call so the model can read tool outputs and craft the final reply\n",
    "        resp2 = client.chat.completions.create(\n",
    "            model=os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\"),\n",
    "            messages=history_messages,\n",
    "            temperature=float(os.getenv(\"OPENAI_TEMPERATURE\",\"0.6\")),\n",
    "            top_p=float(os.getenv(\"OPENAI_TOP_P\",\"0.9\")),\n",
    "            max_tokens=int(os.getenv(\"OPENAI_MAX_TOKENS\",\"400\"))\n",
    "        )\n",
    "        final_msg = resp2.choices[0].message\n",
    "        text = (final_msg.content or \"\").strip()\n",
    "\n",
    "        # Optional: strip the contact nudge unless feedback was actually logged\n",
    "        if not feedback_logged:\n",
    "            text = text.replace(\n",
    "                \"Would you like to leave your name and email so a coach can follow up?\", \"\"\n",
    "            ).strip()\n",
    "\n",
    "        history_messages.append({\"role\": \"assistant\", \"content\": text})\n",
    "        return text, history_messages\n",
    "\n",
    "    # No tools needed â†’ return first response (without the nudge)\n",
    "    text = (msg.content or \"\").strip()\n",
    "    text = text.replace(\n",
    "        \"Would you like to leave your name and email so a coach can follow up?\", \"\"\n",
    "    ).strip()\n",
    "    return text, history_messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de896e86",
   "metadata": {},
   "source": [
    "### 8. AI & UI bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "810ec588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weâ€™ll keep a parallel \"display history\" for the Chatbot (tuples).\n",
    "def respond(user_message, openai_history, display_history):\n",
    "    openai_history = openai_history or []\n",
    "    display_history = display_history or []\n",
    "\n",
    "    try:\n",
    "        answer, openai_history = agentic_chat_once(user_message, openai_history)\n",
    "    except Exception as e:\n",
    "        answer = f\"Sorry, there was an issue contacting the model: {e}\"\n",
    "\n",
    "    display_history = display_history + [(user_message, answer)]\n",
    "    return \"\", openai_history, display_history\n",
    "\n",
    "def load_feedback_table():\n",
    "    try: return pd.read_csv(FEEDBACK_CSV)\n",
    "    except: return pd.DataFrame(columns=[\"timestamp\",\"user_message\",\"model_answer\",\"status\",\"tag\"])\n",
    "\n",
    "def load_leads_table():\n",
    "    try: return pd.read_csv(LEADS_CSV)\n",
    "    except: return pd.DataFrame(columns=[\"timestamp\",\"name\",\"email\",\"notes\",\"source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e6570f",
   "metadata": {},
   "source": [
    "### 9. Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3bdcd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… UI built. Use demo.launch(...) next.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fr/7v5vvmb91wnbf1t19lh721700000gn/T/ipykernel_74621/2668336450.py:10: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(height=420, type=\"tuples\", label=\"Chat\")\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks(title=\"Athlete's Temple â€” Agentic Bot\") as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # Athlete's Temple â€” Gym Manager Bot \n",
    "    â€¢ Answers questions from the business summary  \n",
    "    â€¢ Automatically logs feedback or collects leads via tool calls  \n",
    "    â€¢ Mobile-friendly Gradio UI\n",
    "    \"\"\")\n",
    "\n",
    "    with gr.Tab(\"Chat\"):\n",
    "        chatbot = gr.Chatbot(height=420, type=\"tuples\", label=\"Chat\")\n",
    "        with gr.Row():\n",
    "            msg = gr.Textbox(placeholder=\"Ask about classes, PT, or our missionâ€¦\", label=\"Your Message\")\n",
    "            send = gr.Button(\"Send\", variant=\"primary\")\n",
    "        clear = gr.Button(\"Clear Chat\")\n",
    "\n",
    "        # OpenAI-format history + display history\n",
    "        openai_history_state = gr.State([])   # list of message dicts\n",
    "        display_history_state = gr.State([])  # list of (user, assistant)\n",
    "\n",
    "        send.click(\n",
    "            respond,\n",
    "            inputs=[msg, openai_history_state, display_history_state],\n",
    "            outputs=[msg, openai_history_state, chatbot]\n",
    "        )\n",
    "        msg.submit(\n",
    "            respond,\n",
    "            inputs=[msg, openai_history_state, display_history_state],\n",
    "            outputs=[msg, openai_history_state, chatbot]\n",
    "        )\n",
    "        clear.click(lambda: ([], []), outputs=[openai_history_state, chatbot])\n",
    "\n",
    "    with gr.Tab(\"Leads\"):\n",
    "        name = gr.Textbox(label=\"Name\")\n",
    "        email = gr.Textbox(label=\"Email\")\n",
    "        notes = gr.Textbox(label=\"Notes (optional)\")\n",
    "        submit = gr.Button(\"Submit Lead\", variant=\"primary\")\n",
    "        lead_status = gr.Markdown()\n",
    "\n",
    "        def _submit_lead(name, email, notes):\n",
    "            result = record_customer_interest(name or \"\", email or \"\", notes or \"\", source=\"lead_form\")\n",
    "            return \"Thanks! Your info has been recorded.\" if result.get(\"ok\") else f\"Error: {result}\"\n",
    "\n",
    "        submit.click(_submit_lead, inputs=[name,email,notes], outputs=[lead_status])\n",
    "\n",
    "    with gr.Tab(\"Logs\"):\n",
    "        gr.Markdown(\"### Feedback (Unanswered / Info Requests)\")\n",
    "        fb_btn = gr.Button(\"Refresh Feedback\")\n",
    "        fb_table = gr.Dataframe(headers=[\"timestamp\",\"user_message\",\"model_answer\",\"status\",\"tag\"], wrap=True)\n",
    "\n",
    "        gr.Markdown(\"### Leads (Collected)\")\n",
    "        leads_btn = gr.Button(\"Refresh Leads\")\n",
    "        leads_table = gr.Dataframe(headers=[\"timestamp\",\"name\",\"email\",\"notes\",\"source\"], wrap=True)\n",
    "\n",
    "        fb_btn.click(load_feedback_table, outputs=[fb_table])\n",
    "        leads_btn.click(load_leads_table, outputs=[leads_table])\n",
    "\n",
    "print(\"âœ… UI built. Use demo.launch(...) next.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850d608d",
   "metadata": {},
   "source": [
    "### 10. Launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ff93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* Running on public URL: https://2ec0afd7654bd295e3.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://2ec0afd7654bd295e3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fr/7v5vvmb91wnbf1t19lh721700000gn/T/ipykernel_74621/1310164506.py:16: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"timestamp\": datetime.utcnow().isoformat(),\n",
      "/var/folders/fr/7v5vvmb91wnbf1t19lh721700000gn/T/ipykernel_74621/1310164506.py:3: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"timestamp\": datetime.utcnow().isoformat(),\n"
     ]
    }
   ],
   "source": [
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
